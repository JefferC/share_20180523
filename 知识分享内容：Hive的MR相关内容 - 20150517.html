<html>
<head>
  <title>Evernote Export</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="Evernote Windows/307027 (zh-CN, DDL); Windows/10.0.0 (Win64);"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="423"/>

<div>
<span><div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">内容：</span></font></div><ol><li><div><span style="font-weight: bold;">Hive在什么情况下会起MapReduce</span></div></li><li><div><span style="font-weight: bold;">哪些场景只有Map没有Reduce</span></div></li><li><div><span style="font-weight: bold;">执行计划详解及优化的一些方法</span></div></li></ol><div><br/></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">一、Hive在什么情况下会起MapReduce</span></font></div><div><br/></div><div style="margin-left: 40px;">早期的Hive，几乎任何SQL都是通过MapReduce完成的。</div><div style="margin-left: 40px;">0.10.0版本后，简单的列查询。可以选择通过fetch task来完成。需要设置参数：</div><div style="margin-left: 40px;"><span style="color: rgb(255, 0, 0);">set hive.fetch.task.conversion=more; </span></div><div style="margin-left: 40px;">Select Col_1,Col_2 from Table_1 Limit 10;</div><div style="margin-left: 40px;">最简单的Select * from Table_1也不会起MR任务。</div><div style="margin-left: 40px;">以下有一篇总结：</div><div style="margin-left: 40px;"><div><a href="http://www.cnblogs.com/staryea/p/8570538.html">http://www.cnblogs.com/staryea/p/8570538.html</a></div></div><div style="margin-left: 40px;">从筛选条件看大致上：等值比较、模糊查询（通配符%在任意位置）、不等比较、大小于、Null判断、正则模糊查询（RLike）</div><div style="margin-left: 40px;">这是在SELECT部分为*或者固定字段并且单表查询的情况下。</div><div style="margin-left: 40px;">一旦关联或者出现了聚合函数以及出现排序。则必然会起MR。</div><div style="margin-left: 40px;"><br/></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">二、哪些场景只有Map没有Reduce</span></font></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">Hive获得SQL后，解析为抽象语法树。</div><div style="margin-left: 40px;">此时会有限判断是否需要起MR。随后判断是否需要Reduce Job。</div><div style="margin-left: 40px;">随后会判断Reduce作业的数量。</div><div style="margin-left: 40px;">最简单的SQL类似：Select * From Table Where dt = '20180101';</div><div style="margin-left: 40px;">包括各种普通的筛选条件（大小于，模糊查询，正则模糊查询）</div><div style="margin-left: 40px;">并且没有聚合函数及排序。</div><div style="margin-left: 40px;">另外，还有Map Side Join的关联操作。job只有map阶段而没有Reduce阶段。（同样不包含聚合函数排序等其他因素）</div><div style="margin-left: 40px;">这时候Hive会将reduce task的数量设置为0。</div><div style="margin-left: 40px;">如果在控制台执行会看到Hive打印一行字：</div><div style="margin-left: 40px;">Number of reduce tasks is set to 0 since there's no reduce operator</div><div style="margin-left: 40px;">这样就起了一个Map Only Job。这样的作业在执行过程中跳过了Shuffle和Reduce阶段。因此会比普通的作业使用到更少的集群资源。而且还更快。</div><div style="margin-left: 40px;"><br/></div><div><span style="font-size: 12pt; font-weight: bold;">三、执行计划详解</span></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">查看语句的执行计划在语句前加explain。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">标准的语法：</div><div style="margin-left: 40px;"><div>EXPLAIN [EXTENDED|DEPENDENCY|AUTHORIZATION] query</div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><div><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Explain">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Explain</a></div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><div>执行explain后。控制台会打印出三块内容</div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">第一块是SQL解析后得到的抽象语法树</div><div style="margin-left: 40px;">第二块是步骤依赖</div><div style="margin-left: 40px;">第三块是步骤计划</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">抽象语法树意义不大。单纯的解析并结构化了SQL而已。</div><div style="margin-left: 40px;">也有大神详解：<a href="https://blog.csdn.net/an342647823/article/details/36385479">https://blog.csdn.net/an342647823/article/details/36385479</a></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">步骤依赖：</div><div style="margin-left: 40px;">例：</div><div style="margin-left: 40px;">STAGE DEPENDENCIES:</div><div style="margin-left: 40px;"><span style="font-style: italic;">Stage-1 is a root stage</span></div><div style="margin-left: 40px;"><span style="font-style: italic;">Stage-2 depends on stages: Stage-1</span></div><div style="margin-left: 40px;"><div><span style="font-style: italic;">Stage-0 depends on stages: Stage-2</span></div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">步骤1是初始步骤。</div><div style="margin-left: 40px;">步骤2依赖步骤1。</div><div style="margin-left: 40px;">步骤0依赖步骤2。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">以上例子由于存在依赖无法并行执行。</div><div style="margin-left: 40px;">也有可以并行执行的例子。</div><div style="margin-left: 40px;"><span style="font-style: italic;">Stage-1 is a root stage</span></div><div style="margin-left: 40px;"><div><span style="font-style: italic;">Stage-0 is a root stage</span></div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">这样的话步骤0和步骤1相互之间没有依赖，可以并行。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><span style="color: rgb(106, 0, 129);">关于并行优化：</span></div><div style="margin-left: 40px;"><span style="color: rgb(106, 0, 129);">set hive.exec.parallel=true;</span></div><div style="margin-left: 40px;"><span style="color: rgb(106, 0, 129);">set hive.exec.parallel.thread.number=10;</span></div><div style="margin-left: 40px;"><span style="color: rgb(106, 0, 129);">上面第一个参数开启任务并行</span></div><div style="margin-left: 40px;"><span style="color: rgb(106, 0, 129);">第二个参数设置单sql并行的MR job个数。</span></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">步骤计划：</div><div style="margin-left: 40px;">也就是操作树。</div><div style="margin-left: 40px;">这里分不同的stage步骤。每个stage就是一个MapReduce。</div><div style="margin-left: 40px;">每个Stage包含Map操作树和Reduce操作树。</div><div style="margin-left: 40px;">以一个insert语句为例</div><div style="margin-left: 40px;">FROM src INSERT OVERWRITE TABLE dest_g1 SELECT src.key, sum(substr(src.value,4)) GROUP BY src.key;</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">该SQL包含三个步骤。依赖分别是：</div><div style="margin-left: 40px;"><span style="font-style: italic;">Stage-1 is a root stage</span></div><div style="margin-left: 40px;"><span style="font-style: italic;">Stage-2 depends on stages: Stage-1</span></div><div style="margin-left: 40px;"><div><span style="font-style: italic;">Stage-0 depends on stages: Stage-2</span></div><div><br/></div></div><div style="margin-left: 40px;">执行计划：</div><div style="margin-left: 40px;"><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>STAGE PLANS:</div><div>  Stage: Stage-1</div><div>    Map Reduce</div><div>      Alias -&gt; Map Operator Tree:</div><div>        src</div><div>            Reduce Output Operator</div><div>              key expressions:</div><div>                    expr: key</div><div>                    type: string</div><div>              sort order: +</div><div>              Map-reduce partition columns:</div><div>                    expr: rand()</div><div>                    type: double</div><div>              tag: -1</div><div>              value expressions:</div><div>                    expr: substr(value, 4)</div><div>                    type: string</div><div>      Reduce Operator Tree:</div><div>        Group By Operator</div><div>          aggregations:</div><div>                expr: sum(UDFToDouble(VALUE.0))</div><div>          keys:</div><div>                expr: KEY.0</div><div>                type: string</div><div>          mode: partial1</div><div>          File Output Operator</div><div>            compressed: false</div><div>            table:</div><div>                input format: org.apache.hadoop.mapred.SequenceFileInputFormat</div><div>                output format: org.apache.hadoop.mapred.SequenceFileOutputFormat</div><div>                name: binary_table</div><div>  Stage: Stage-2</div><div>    Map Reduce</div><div>      Alias -&gt; Map Operator Tree:</div><div>        /tmp/hive-zshao/67494501/106593589.10001</div><div>          Reduce Output Operator</div><div>            key expressions:</div><div>                  expr: 0</div><div>                  type: string</div><div>            sort order: +</div><div>            Map-reduce partition columns:</div><div>                  expr: 0</div><div>                  type: string</div><div>            tag: -1</div><div>            value expressions:</div><div>                  expr: 1</div><div>                  type: double</div><div>      Reduce Operator Tree:</div><div>        Group By Operator</div><div>          aggregations:</div><div>                expr: sum(VALUE.0)</div><div>          keys:</div><div>                expr: KEY.0</div><div>                type: string</div><div>          mode: final</div><div>          Select Operator</div><div>            expressions:</div><div>                  expr: 0</div><div>                  type: string</div><div>                  expr: 1</div><div>                  type: double</div><div>            Select Operator</div><div>              expressions:</div><div>                    expr: UDFToInteger(0)</div><div>                    type: int</div><div>                    expr: 1</div><div>                    type: double</div><div>              File Output Operator</div><div>                compressed: false</div><div>                table:</div><div>                    input format: org.apache.hadoop.mapred.TextInputFormat</div><div>                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat</div><div>                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</div><div>                    name: dest_g1</div><div>  Stage: Stage-0</div><div>    Move Operator</div><div>      tables:</div><div>            replace: true</div><div>            table:</div><div>                input format: org.apache.hadoop.mapred.TextInputFormat</div><div>                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat</div><div>                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</div><div>                name: dest_g1</div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">先看Stage-1</div><div style="margin-left: 40px;">第一行：Stage： Stage-1   // 相当于一个tag。表示这段是Stage-1</div><div style="margin-left: 40px;">第二行：Map Reduce   // 表示需要执行MapReduce</div><div style="margin-left: 40px;">第三行：Alias -&gt; Map Operator Tree:  // 表示Map操作树</div><div style="margin-left: 40px;">第四行：src    // 这个是操作的表</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">map操作：</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>Reduce Output Operator   // Map段的本地简化操作，最终将结果给到对应的Reduce操作中。所有这种xxxx Operator都是操作符</div><div>  key expressions:       // 键表达式 这里先的key表达是src表中的字段，type后面是它的类型，这里是string</div><div>        expr: key</div><div>        type: string</div><div>  sort order: +          // 排序，这里只有一个key。因此只有一个符号。如有多个key则有多个。+是升序，-是降序</div><div>  Map-reduce partition columns:  // hadoop partition</div><div>        expr: rand()</div><div>        type: double</div><div>  tag: -1</div><div>  value expressions:     // 值的表达式</div><div>        expr: substr(value, 4)   // 这里是于SQL中一样的表达式，类型是string</div><div>        type: string</div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">下面是Reduce的操作树：</div><div style="margin-left: 40px;"><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>Group By Operator                      // 分组操作</div><div>  aggregations:                        // 聚合操作，expr是表达式。这段SQL是sum操作。后面UDFToDouble将值转成了double形（map传过来的是string）</div><div>        expr: sum(UDFToDouble(VALUE.0))</div><div>  keys:                                // 键，表达式是KEY.0 这里的0和VALUE中的0都是值键或值的组中的元素，即列名。type为string</div><div>        expr: KEY.0</div><div>        type: string</div><div>  mode: partial1                       // 模式，这个partial1是指:从原始数据到部分数据聚合。是MapReduce的Map阶段</div><div>  File Output Operator                 // 文件输出操作，compressed false不压缩。这里是输出到文件了</div><div>    compressed: false                  // 后面分别指定了结果输出到表。并且指定了输入文件类型及输出文件类型。</div><div>    table:</div><div>        input format: org.apache.hadoop.mapred.SequenceFileInputFormat</div><div>        output format: org.apache.hadoop.mapred.SequenceFileOutputFormat</div><div>        name: binary_table</div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">可以看到，Stage-1将数据全部拿到后生成键值对给到reduce。reduce进行了分组和聚合操作生成新的键值对并输出到二进制文本。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">接下来看依赖于Stage-1的Stage-2。</div><div style="margin-left: 40px;">前面都是一样的。</div><div style="margin-left: 40px;">以下是Map操作树：</div><div style="margin-left: 40px;"><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>Alias -&gt; Map Operator Tree:</div><div>/tmp/hive-zshao/67494501/106593589.10001  // 该目录应该是Stage-1输出的临时文本文件。以该文件作为Stage-2 Map的输入</div><div>  Reduce Output Operator                  // 输出到本地Reduce操作。这里没有做什么操作。就是拿了然后输出。</div><div>    key expressions:</div><div>          expr: 0</div><div>          type: string</div><div>    sort order: +</div><div>    Map-reduce partition columns:</div><div>          expr: 0</div><div>          type: string</div><div>    tag: -1</div><div>    value expressions:</div><div>          expr: 1</div><div>          type: double</div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">以下是Reduce操作树</div><div style="margin-left: 40px;"><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>Group By Operator        // 分组，关于键进一步聚合，做sum。（Stage-1的模式是partial1,是部分数据的聚合）模式为final：完整数据聚合</div><div>  aggregations:</div><div>        expr: sum(VALUE.0)</div><div>  keys:</div><div>        expr: KEY.0</div><div>        type: string</div><div>  mode: final</div><div>  Select Operator        // 查询操作，这里的0，1是列名。本例中0是key，1是聚合的值</div><div>    expressions:</div><div>          expr: 0</div><div>          type: string</div><div>          expr: 1</div><div>          type: double</div><div>    Select Operator      // 查询操作，对列0做了UDFToInteger操作。输出成了int</div><div>      expressions:</div><div>            expr: UDFToInteger(0)</div><div>            type: int</div><div>            expr: 1</div><div>            type: double</div><div>      File Output Operator  // 输出为文件。不压缩。这里多了指定了个serde序列器。</div><div>        compressed: false</div><div>        table:</div><div>            input format: org.apache.hadoop.mapred.TextInputFormat</div><div>            output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat</div><div>            serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</div><div>            name: dest_g1</div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">Stage-2对完整数据做了聚合。输出到txt文件</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">最后是Stage-0</div><div style="margin-left: 40px;"><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>Move Operator                // 非常好理解。移动操作。并将原来的文件替换了。</div><div>  tables:</div><div>        replace: true</div><div>        table:</div><div>            input format: org.apache.hadoop.mapred.TextInputFormat</div><div>            output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat</div><div>            serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</div><div>            name: dest_g1</div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">Stage-0是一个非MapReduce操作。文件系统关联的步骤。将Stage-2的结果从临时目录移动到了dest_g1的目录下。并替换了原来该目录下文件。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">本例只是个简单的单表聚合插入的sql。并没有涵盖特别多的Hive操作内容。</div><div style="margin-left: 40px;">Hive的操作符一般包含这些：<span style="color: rgb(26, 144, 185);">TableScanOperator，SelectOperator，FilterOperator，JoinOperator，GroupByOperator，ReduceSinkOperator</span></div><div style="margin-left: 40px;">看名字就知道是什么操作了。需要说明一下的事最后一个Reduce Sink Operator。</div><div style="margin-left: 40px;"><div>ReduceSinkOperator将Map端的字段组合序列化为Reduce Key/value, Partition Key，只可能出现在Map阶段，同时也标志着Hive生成的MapReduce程序中Map阶段的结束。</div></div><div style="margin-left: 40px;">Reduce Sink Operator通常在SQL包含排序，关联等操作的时候会有。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">以下举几个以上例子中没有出现的操作的例子：</div><div style="margin-left: 40px;">TableScanOperator：</div><div style="margin-left: 40px;"><div><span style="font-style: italic;">TableScan</span></div></div><div style="margin-left: 40px;"><div><span style="font-style: italic;">     alias: mytb</span></div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><div>FilterOperator：</div></div><div style="margin-left: 40px;"><div><span style="font-style: italic;">Filter Operator</span></div></div><div style="margin-left: 40px;"><span style="font-style: italic;">    predicate: (((deal_id = '') or (deal_id = '-')) or deal_id is null) (type: boolean)</span></div><div style="margin-left: 40px;"><div><br/></div></div><div style="margin-left: 40px;"><div>JoinOperator：</div></div><div style="margin-left: 40px;"><span style="font-style: italic;"># TODO</span></div><div style="margin-left: 40px;"><div><br/></div></div><div style="margin-left: 40px;"><div>ReduceSinkOperator：</div></div><div style="margin-left: 40px;"><span style="font-style: italic;"># TODO</span></div><div style="margin-left: 40px;"><div><br/></div></div><div style="margin-left: 40px;">每个Operator都是个Java类。包含了属性和各种方法。对于深度了解Hive有兴趣的同学。可以看源码。</div><div style="margin-left: 40px;">实际上，如果能看懂源码。看懂hive执行计划什么的都是小case了。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">另外，还有一些与通常情况不太一样的执行计划。例如一个被判断为本地模式可以执行的SQL。</div><div style="margin-left: 40px;">实际上如果被判断为本地模式执行的SQL。也没有去看执行计划的必要了。它必然快速。且数据量不大。优化的需求相对来说不大。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><span style="font-weight: bold;">本地MapReduce</span></div><div style="margin-left: 40px;">也就是Hive优化中大名鼎鼎的本地模式。仅在本地执行MR。效率非常高。</div><div style="margin-left: 40px;"><div>SET hive.exec.mode.local.auto = true</div></div><div style="margin-left: 40px;">开启自动本地模式。（Cloudera的CDH平台该参数是默认开启的。）</div><div style="margin-left: 40px;">对于满足一下三个条件的作业，Hive将会启动本地模式。</div><div style="margin-left: 40px;">条件1：输入Map的数据小于参数hive.exec.mode.local.auto.inputbytes.max</div><div style="margin-left: 40px;">条件2：Map的作业数量小于参数hive.exec.mode.local.auto.tasks.max</div><div style="margin-left: 40px;">条件3：Reduce作业数小于等于1（可以设置：set mapred.reduce.tasks = n(n为自然数)，或者设置每个Reduce作业的数据量：hive.exec.reducers.bytes.per.reducer）</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">决定map作业数量的条件有两个：</div><div style="margin-left: 40px;">1、输入的文件个数</div><div style="margin-left: 40px;">2、大文件的大小</div><div style="margin-left: 40px;">简单来说就是小于hdfs一个block的文件有一个就起一个map。反过来大于这个大小的文件会切成符合条件的多个并且起同等数量的map作业。</div><div style="margin-left: 40px;">不过这不是绝对。如果设置了合并小文件。map作业数可能减少。</div><div style="margin-left: 40px;">关于该设置，需要设置的参数有：hive.input.format = <a href="http://org.apache.hadoop.hive.ql.io.combinehiveinputformat/">org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</a>（这个参数使Hive在map前执行了合并小文件操作）</div><div style="margin-left: 40px;">并且设置 mapred.max.split.size（hive每个map的最大文件的大小）</div></div><div style="margin-left: 40px;"><div>mapred.min.split.size.per.node（每个节点分割文件的最小大小）</div></div><div style="margin-left: 40px;"><div>mapred.min.split.size.per.rack（这个是指每个交换机上分割文件的最小大小）</div></div><div style="margin-left: 40px;">该设置在输入文件中小文件很多的情况下可以增加执行的效率。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><span style="font-size: 11pt; font-weight: bold;">谈一下从执行计划可以得出的优化方案</span></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">前面已经提到一个方式。如果job之间相互不存在依赖。可以设置并行。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">目前，如果Hive版本足够高的话。可以在执行计划中看到每一步的数据量。</div><div style="margin-left: 40px;">在输入数据量不大的情况下。可以考虑修改参数，令hive本地模式执行sql。</div><div style="margin-left: 40px;"><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>Map Reduce Local Work</div><div>  Alias -&gt; Map Local Tables:</div><div>    b</div><div>      Fetch Operator</div><div>        limit: -1</div><div>  Alias -&gt; Map Local Operator Tree:</div><div>    b</div><div>      TableScan</div><div>        alias: b</div><div>        Statistics: Num rows: 2 Data size: 2 Basic stats: COMPLETE Column stats: NONE</div><div>        Filter Operator</div><div>          predicate: (id = 1) (type: boolean)</div><div>          Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE</div><div>          HashTable Sink Operator</div><div>            keys:</div><div>              0 id (type: int)</div><div>              1 id (type: int)</div><div><br/></div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><div>多表关联尽量用同一个key来做关联条件。这一点在执行计划上体现得非常突出。</div></div><div style="margin-left: 40px;">举个例子：</div><div style="margin-left: 40px;">SQL1：</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>explain select * from thirdtb c join firsttb a on a.id = c.tid left join secondtb b on b.id = c.tid;</div><div>STAGE DEPENDENCIES:</div><div>  Stage-5 is a root stage</div><div>  Stage-4 depends on stages: Stage-5</div><div>  Stage-0 depends on stages: Stage-4</div><div><br/></div><div>STAGE PLANS:</div><div>  Stage: Stage-5</div><div>    Map Reduce Local Work</div><div>      Alias -&gt; Map Local Tables:</div><div>        a</div><div>          Fetch Operator</div><div>            limit: -1</div><div>        b</div><div>          Fetch Operator</div><div>            limit: -1</div><div>      Alias -&gt; Map Local Operator Tree:</div><div>        a</div><div>          TableScan</div><div>            alias: a</div><div>            Statistics: Num rows: 2 Data size: 2 Basic stats: COMPLETE Column stats: NONE</div><div>            HashTable Sink Operator</div><div>              keys:</div><div>                0 tid (type: int)</div><div>                1 id (type: int)</div><div>                2 id (type: int)</div><div>        b</div><div>          TableScan</div><div>            alias: b</div><div>            Statistics: Num rows: 2 Data size: 2 Basic stats: COMPLETE Column stats: NONE</div><div>            HashTable Sink Operator</div><div>              keys:</div><div>                0 tid (type: int)</div><div>                1 id (type: int)</div><div>                2 id (type: int)</div><div><br/></div><div>  Stage: Stage-4</div><div>    Map Reduce</div><div>      Map Operator Tree:</div><div>          TableScan</div><div>            alias: c</div><div>            Statistics: Num rows: 2 Data size: 10 Basic stats: COMPLETE Column stats: NONE</div><div>            Map Join Operator</div><div>              condition map:</div><div>                   Inner Join 0 to 1</div><div>                   Left Outer Join0 to 2</div><div>              keys:</div><div>                0 tid (type: int)</div><div>                1 id (type: int)</div><div>                2 id (type: int)</div><div>              outputColumnNames: _col0, _col1, _col2, _col6, _col10</div><div>              Statistics: Num rows: 4 Data size: 22 Basic stats: COMPLETE Column stats: NONE</div><div>              Select Operator</div><div>                expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col6 (type: int), _col10 (type: int)</div><div>                outputColumnNames: _col0, _col1, _col2, _col3, _col4</div><div>                Statistics: Num rows: 4 Data size: 22 Basic stats: COMPLETE Column stats: NONE</div><div>                File Output Operator</div><div>                  compressed: false</div><div>                  Statistics: Num rows: 4 Data size: 22 Basic stats: COMPLETE Column stats: NONE</div><div>                  table:</div><div>                      input format: org.apache.hadoop.mapred.TextInputFormat</div><div>                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</div><div>                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</div><div>      Local Work:</div><div>        Map Reduce Local Work</div><div><br/></div><div>  Stage: Stage-0</div><div>    Fetch Operator</div><div>      limit: -1</div><div>      Processor Tree:</div><div>        ListSink</div><div><br/></div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">SQL2：</div><div style="margin-left: 40px;"><br/></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>explain select * from thirdtb c join firsttb a on a.id = c.tid left join secondtb b on b.id = c.oid;</div><div>STAGE DEPENDENCIES:</div><div>  Stage-7 is a root stage</div><div>  Stage-5 depends on stages: Stage-7</div><div>  Stage-0 depends on stages: Stage-5</div><div><br/></div><div>STAGE PLANS:</div><div>  Stage: Stage-7</div><div>    Map Reduce Local Work</div><div>      Alias -&gt; Map Local Tables:</div><div>        a</div><div>          Fetch Operator</div><div>            limit: -1</div><div>        b</div><div>          Fetch Operator</div><div>            limit: -1</div><div>      Alias -&gt; Map Local Operator Tree:</div><div>        a</div><div>          TableScan</div><div>            alias: a</div><div>            Statistics: Num rows: 2 Data size: 2 Basic stats: COMPLETE Column stats: NONE</div><div>            Filter Operator</div><div>              predicate: id is not null (type: boolean)</div><div>              Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: NONE</div><div>              HashTable Sink Operator</div><div>                keys:</div><div>                  0 tid (type: int)</div><div>                  1 id (type: int)</div><div>        b</div><div>          TableScan</div><div>            alias: b</div><div>            Statistics: Num rows: 2 Data size: 2 Basic stats: COMPLETE Column stats: NONE</div><div>            HashTable Sink Operator</div><div>              keys:</div><div>                0 _col1 (type: int)</div><div>                1 id (type: int)</div><div><br/></div><div>  Stage: Stage-5</div><div>    Map Reduce</div><div>      Map Operator Tree:</div><div>          TableScan</div><div>            alias: c</div><div>            Statistics: Num rows: 2 Data size: 10 Basic stats: COMPLETE Column stats: NONE</div><div>            Filter Operator</div><div>              predicate: tid is not null (type: boolean)</div><div>              Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE</div><div>              Map Join Operator</div><div>                condition map:</div><div>                     Inner Join 0 to 1</div><div>                keys:</div><div>                  0 tid (type: int)</div><div>                  1 id (type: int)</div><div>                outputColumnNames: _col0, _col1, _col2, _col6</div><div>                Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE</div><div>                Map Join Operator</div><div>                  condition map:</div><div>                       Left Outer Join0 to 1</div><div>                  keys:</div><div>                    0 _col1 (type: int)</div><div>                    1 id (type: int)</div><div>                  outputColumnNames: _col0, _col1, _col2, _col6, _col10</div><div>                  Statistics: Num rows: 2 Data size: 2 Basic stats: COMPLETE Column stats: NONE</div><div>                  Select Operator</div><div>                    expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col6 (type: int), _col10 (type: int)</div><div>                    outputColumnNames: _col0, _col1, _col2, _col3, _col4</div><div>                    Statistics: Num rows: 2 Data size: 2 Basic stats: COMPLETE Column stats: NONE</div><div>                    File Output Operator</div><div>                      compressed: false</div><div>                      Statistics: Num rows: 2 Data size: 2 Basic stats: COMPLETE Column stats: NONE</div><div>                      table:</div><div>                          input format: org.apache.hadoop.mapred.TextInputFormat</div><div>                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</div><div>                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</div><div>      Local Work:</div><div>        Map Reduce Local Work</div><div><br/></div><div>  Stage: Stage-0</div><div>    Fetch Operator</div><div>      limit: -1</div><div>      Processor Tree:</div><div>        ListSink</div><div><br/></div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">比较明显。用相同key做关联的SQL1的操作符为10个，而非同一key的SQL2则需要13个操作符来完成关联。</div><div style="margin-left: 40px;">在可选的情况下。尽量多表关联使用同一个key来关联是消耗集群资源最低，也是最为快速的执行的方案。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">接下来不再一一举例。仅提出一些优化的方案：</div><div style="margin-left: 40px;">表关联的时候，小表在前。或指定大表。情况允许下，尽量使用map端join（可以使关联部分的MR任务转为Map Only Job）。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><div>复杂sql使得执行计划复杂化。建议做中间表。简化执行计划。</div></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">此外，可能在执行计划上没有体现。但是实际数据的问题导致的性能低下</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">具体的执行计划请大家自行尝试。</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;"><div><a href="http://www.cnblogs.com/ITtangtang/p/7683028.html">http://www.cnblogs.com/ITtangtang/p/7683028.html</a></div></div><div style="margin-left: 40px;"><br/></div></span>
</div></body></html> 